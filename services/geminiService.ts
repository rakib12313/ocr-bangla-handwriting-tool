import { GoogleGenAI } from "@google/genai";
import { BANGLA_OCR_SYSTEM_PROMPT } from '../constants';
import { ProcessingResult } from '../types';

let aiInstance: GoogleGenAI | null = null;

const getAIInstance = (): GoogleGenAI => {
  if (!aiInstance) {
    if (!process.env.API_KEY) {
      throw new Error("API Key not found in environment variables.");
    }
    aiInstance = new GoogleGenAI({ apiKey: process.env.API_KEY });
  }
  return aiInstance;
};

const fileToGenerativePart = (base64Data: string, mimeType: string) => {
  return {
    inlineData: {
      data: base64Data,
      mimeType,
    },
  };
};

export const performOCR = async (
  imageBase64: string, 
  mimeType: string,
  model: string
): Promise<ProcessingResult> => {
  try {
    const ai = getAIInstance();
    const imagePart = fileToGenerativePart(imageBase64, mimeType);

    const response = await ai.models.generateContent({
      model: model,
      contents: {
        parts: [imagePart, { text: "Transcribe this Bangla handwriting." }],
      },
      config: {
        systemInstruction: BANGLA_OCR_SYSTEM_PROMPT,
        temperature: 0.1, // Low temperature for factual transcription
      }
    });

    const text = response.text || "";
    
    // Basic validation to ensure we got something
    if (!text) {
      throw new Error("No text generated by the model.");
    }

    return {
      text: text.trim(),
      confidence: 0.95,
    };

  } catch (error: any) {
    console.error("OCR Service Error:", error);
    throw new Error(error.message || "Failed to process image.");
  }
};
